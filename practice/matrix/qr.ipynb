{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Разложения с ортогональными матрицами"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Одним из наиболее используемых на практике разложений (см. также ранее изученное [LU разложение](lu.ipynb)) часто используется [QR разложение](https://en.wikipedia.org/wiki/QR_decomposition), т.е. представление произвольной (даже не обязательно квадратной) матрицы $A$\n",
    "в виде произведения \n",
    "$$A=QR,$$\n",
    "где матрица $Q$ ортогональна (или [унитарна](https://en.wikipedia.org/wiki/Unitary_matrix) в комплексном случае), т.е. $Q^*Q=1$,\n",
    "а матрица $R$ [верхнетреугольная](https://en.wikipedia.org/wiki/Triangular_matrix). \n",
    "QR разложение может быть, например, использовано для решения систем, $Ax=B$,\n",
    "так как решение в данном случае может быть найдено из системы $Rx=Q^*B$, что можно сделать эффективно методом [обратных подстановок](https://en.wikipedia.org/wiki/Triangular_matrix#Forward_and_back_substitution). \n",
    "Для нахождения LU разложения мы ранее использовали [преобразования Гаусса](https://en.wikipedia.org/wiki/Gaussian_elimination), аналогично для вычисления QR разложения и подобных используются отражения Хаусхоледар и вращения Гивенса. \n",
    "\n",
    "Преобразование вида\n",
    "$$\n",
    "P = 1-2\\frac{|v\\rangle\\langle v|}{v^2}\n",
    "$$\n",
    "называется [преобразованием (отражением) Хаусхолдера](https://en.wikipedia.org/wiki/Householder_transformation).\n",
    "Здесь $1$ обозначает тождественный оператор, числитель дроби содержит [внешнее произведение](https://en.wikipedia.org/wiki/Outer_product) вектора $v$ на себя, а знаменатель - скалярный квадрат вектора $v$.\n",
    "Преобразование Хаусхолдера используется для обнуления в матрице всех элементов столбца, кроме одного (см. задание ниже).\n",
    "\n",
    "Вторым распространенным преобразованием при разложении с ортогональными матрицами является [вращение Гивенса](https://en.wikipedia.org/wiki/Givens_rotation):\n",
    "$$G=1-|v\\rangle\\langle v|-|u\\rangle\\langle u|\n",
    "+\\begin{pmatrix}|v\\rangle & |u\\rangle\\end{pmatrix}\n",
    "\\begin{pmatrix}\\cos\\theta & \\sin\\theta\\\\-\\sin\\theta & \\cos\\theta\\end{pmatrix}\n",
    "\\begin{pmatrix}\\langle v| \\\\ \\langle u|\\end{pmatrix},$$\n",
    "где вектора $u$ и $v$ ортогональны и нормированы $u^2=v^2=1$, $u\\cdot v=0$.\n",
    "Вещественное число $\\theta$ задает [угол поворота](https://en.wikipedia.org/wiki/Rotation_matrix) в плоскости, натянутой на вектора $u$, $v$.\n",
    "Вращение Гивенса используется для обнуления одного коэффициента вектора (см. задание ниже).\n",
    "\n",
    "Отражения Хаусхолдера и вращения Гивенса являются возмущениями ранга один и два соответственно тождественного оператора,\n",
    "т.е. они действуют на все вектора как тождественный оператор, кроме одномерного и двумерного подпространств, соответственно. \n",
    "Малый ранг возмущения позволяет вычислять действие таких преобразований на вектор значительно быстрее, чем умножение на заполненную матрицу."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Задания\n",
    "\n",
    "1. Покажите, что в базисе, содержащим вектора $u$ и $v$, матрица вращений Гивенса отличается от единичной только блоком $2\\times 2$.\n",
    "\n",
    "1. Докажите, что преобразование Хаусхолдера ортогональное и симметрическое, а вращения Гивенса - ортогональное преобразование. Сравните с преобразованиями Гаусса.\n",
    "\n",
    "1. Покажите, что для любых векторов $x$ и $e$ можно найти такое $v$, что отражение Хаусхолдера переводит $x$ в вектор кратный $e$. Убедитесь, что если в качестве $e$ взять базисный вектор, то с помощью отражения Хаусхолдера можно обратить все элементы одного столбца матрицы, кроме одного, в ноль.\n",
    "\n",
    "1. Покажите, что преобразованием Гивенса всегда можно обратить один заданный элемент вектора в ноль. Убедитесь, что также в ноль можно обратить один желаемый элемент матрицы.\n",
    "\n",
    "1. Пользуясь тем, что преобразование Хаусхолдера модифицирует только одномерное подпространство, опишите алгоритм последовательного применения отражений Хаусхолдера для приведения матрицы к верхнетреугольному виду. Как этот алгоритм связан с QR разложением?\n",
    "\n",
    "1. Аналогично предыдущему пункту, опишите алгоритм применения вращений Гивенса для приведения матрицы к треугольному виду.\n",
    "\n",
    "1. Реализуйте один из вариантов QR разложения.\n",
    "\n",
    "1. Как можно выполнить QR разложение в блочном виде? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Помимо решения систем QR разложение находит свое применение во множестве других задач, например, при вычисление [спектрального разложения](https://en.wikipedia.org/wiki/QR_algorithm).\n",
    "Мы же сейчас рассмотрим [метод наименьших квадратов](https://en.wikipedia.org/wiki/Least_squares),\n",
    "один из наиболее распространенных методов [регрессионного анализа](https://en.wikipedia.org/wiki/Regression_analysis).\n",
    "\n",
    "Допустим мы задались некоторой моделью $f(x,\\beta)=y$, сопоставляющей переменной $x$ переменную $y$\n",
    "по некоторому закону, содержащему параметр (вектор параметров) $\\beta$.\n",
    "Допустим у нас есть набор эмпирических наблюдений пар этих переменных $(x_k, y_k)$.\n",
    "Мы хотим найти такое значение параметра, при котором ошибки $r_k=f(x_k,\\beta)-y_k$\n",
    "предсказаний модели будут минимальными.\n",
    "Можно использовать разные меры ошибок, выбор меры зависит от специфики задачи,\n",
    "однако наиболее простым выбором является среднеквадратическая ошибка\n",
    "$$\n",
    "R[\\beta]=\\sum_k r_k^2,\n",
    "$$\n",
    "которая и приводит нас к методу наименьших квадратов.\n",
    "В предположении дифференцируемости функции $f$, квадратичная ошибка также дифференцируема,\n",
    "что дает простое необходимое условие оптимальности параметра $\\beta$:\n",
    "$$\n",
    "\\frac{\\partial R}{\\partial \\beta} = 2\\sum_k r_k\\frac{\\partial f(x_k,\\beta)}{\\partial\\beta} = 0. \n",
    "$$\n",
    "В общем виде это уравнение нелинейное и решается [оптимизационными методами](https://en.wikipedia.org/wiki/Mathematical_optimization).\n",
    "Однако есть простой частный случай, когда решение может быть предъявлено явно.\n",
    "Пусть \n",
    "$$f(x,\\beta)=\\sum_j \\beta_j f_j(x),$$\n",
    "т.е. пусть наша модель линейна по вектору параметров $\\beta$.\n",
    "В качестве примера хорошо держать в голове разложение по многочленам фиксированной степени,\n",
    "в этом случае $f_j(x)=x^j$ или разложение по базису Фурье $f_j(x)=\\cos jx$ \n",
    "(метод наименьших квадратов, однако, не самый быстрый способ получить эти разложения).\n",
    "В линейной модели необходимое условие оптимальности (являющееся и достаточным в этом случае),\n",
    "принимает вид линейной системы уравнений на $\\beta$:\n",
    "$$\\sum_k r_k\\cdot f_j(x_k)=\\sum_k (\\sum_{j'}\\beta_{j'} f_{j'}(x_k)-y_k)\\cdot f_j(x_k)=0\\forall j.$$ \n",
    "Введем матрицу $A$, $A_{kj}=f_j(x_k)$, вектора $\\beta=(\\beta_j)$, $Y=(y_k)$,\n",
    "тогда систему можно записать в матричном виде:\n",
    "$$\n",
    "A^T(A\\beta-Y)=0.\n",
    "$$\n",
    "Вектор $R=A\\beta-Y$ называется невязкой, по сути решаемая задача сводилась к минимизации невязке в норме $l_2$.\n",
    "Искомые оптимиальные параметры модели находятся из системы\n",
    "$$A^TA\\beta=A^TY,$$\n",
    "с симметрической матрицей. \n",
    "В случае невырожденной квадратной матрицы $A$ решение задачи наименьших квадртов давалось бы из уравнения $A\\beta=Y$.\n",
    "На практике обычно число измерений $Y$ намного больше, чем число параметров $\\beta$, поэтому систем $A\\beta=Y$ оказывается переопределенной, и метод наименьших квадратов дает лучшее возможное решение (в смысле наименьше ошибки).\n",
    "Система с матрицей $A^TA$ с точки зрения численных методов хуже, так как число обусловленности у этой матрицы больше\n",
    "$$\\kappa(A^TA)=\\kappa(A)^2,$$\n",
    "а значит больше погрешность решения и ниже скорость сходимости итерационных методов.\n",
    "Используя QR разложения и подобные можно предложить альтернативные методы решения. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Задания\n",
    "\n",
    "9. Предложите способ решения задачи наименьших квадратов используя SVD разложение.\n",
    "\n",
    "9. Аналогично, используя QR разложение.\n",
    "\n",
    "9. Реализуйте решение задачи линейной регрессии, используя QR разложение. Исплользуйте эффективное представление преобразований Хаусхолдера или Гаусса, для минимизации сложности вычислений."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Литература\n",
    "\n",
    "1. Gene H. Golub, Charles F. Van Loan. Matrix Computations. Глава 5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
